{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtfixlH3CSXIgTtFoRvl73"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Evaluate the Model (Check Accuracy)"],"metadata":{"id":"YdEn1r0eZ9Ju"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# Assuming you want a simple linear model for demonstration:\n","class SimpleModel(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(SimpleModel, self).__init__()\n","        self.linear = nn.Linear(input_size, output_size)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","# Replace these with your actual input and output sizes\n","input_size = 10\n","output_size = 5\n","\n","# Create an instance of your model\n","model = SimpleModel(input_size, output_size)\n","\n","model.eval()  # Important: turns off training-specific layers (like Dropout, BatchNorm)\n","\n","# Assuming X_train and y_train are your training data and labels\n","# Replace these with your actual data loading or creation logic\n","X_train = torch.randn(100, input_size)  # Example: 100 samples with input_size features\n","y_train = torch.randint(0, output_size, (100,))  # Example: 100 random labels\n"],"metadata":{"id":"fJVXQuaOamTk","executionInfo":{"status":"ok","timestamp":1745844197313,"user_tz":-360,"elapsed":190,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","# We don't need gradients when evaluating\n","with torch.no_grad():\n","    # 1. Pass input through model\n","    outputs = model(X_train)\n","\n","    # 2. Get predicted class (highest score)\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # 3. Calculate how many correct predictions\n","    correct = (predicted == y_train).sum().item()\n","\n","    # 4. Calculate accuracy\n","    total = y_train.size(0)\n","    accuracy = correct / total * 100\n","\n","    print(f'Accuracy: {accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjo1xPymaNYg","executionInfo":{"status":"ok","timestamp":1745844198810,"user_tz":-360,"elapsed":20,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}},"outputId":"58662b5b-37d5-420c-9bec-b47f13fedc9e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 17.00%\n"]}]},{"cell_type":"markdown","source":["##Save the Model"],"metadata":{"id":"V4wkvflAcYNT"}},{"cell_type":"code","source":["#  Save the model\n","\n","# Save model's parameters (weights)\n","torch.save(model.state_dict(), 'mymodel.pth')  # Saves in a file 'mymodel.pth'\n","print(\"Model saved!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXlpvIltcZUE","executionInfo":{"status":"ok","timestamp":1745844574112,"user_tz":-360,"elapsed":9,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}},"outputId":"ba0dab39-2e0e-4f62-9e9b-020bf113394f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved!\n"]}]},{"cell_type":"markdown","source":["##Loading the Model"],"metadata":{"id":"iXeZ0w7LcmLv"}},{"cell_type":"code","source":["# Load the model\n","\n","# First, create the model object again using the correct class SimpleModel\n","model_loaded = SimpleModel(input_size, output_size) # Using the previously defined input and output sizes\n","\n","# Load the saved weights into this model\n","model_loaded.load_state_dict(torch.load('mymodel.pth'))\n","\n","# Always call eval() after loading for inference\n","model_loaded.eval()\n","\n","print(\"Model loaded and ready for evaluation!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eE16AeYaclip","executionInfo":{"status":"ok","timestamp":1745844692303,"user_tz":-360,"elapsed":147,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}},"outputId":"f794aa94-b121-4557-d433-6c9b9f2bbb09"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded and ready for evaluation!\n"]}]}]}