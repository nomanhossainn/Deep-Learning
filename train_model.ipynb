{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOgEfy8yyx5M7fLbVUlZFSk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##What we will do now:\n","- Define a Loss Function (how bad our prediction is).\n","- Define an Optimizer (how to improve the model).\n","- Write a Training Loop (to actually train the model).\n","- Test the training output.\n","- Evaluate the Model (Check Accuracy)"],"metadata":{"id":"9bLnV3wPMPKA"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","#Create model\n","\n","class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.fc1 = nn.Linear(5, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 2)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        return x\n","\n","model = MyModel()  # Create an instance of the model\n"],"metadata":{"id":"Rf2h3XqfMsXU","executionInfo":{"status":"ok","timestamp":1745844040682,"user_tz":-360,"elapsed":3411,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["- nn.CrossEntropyLoss()\t--> Measures how wrong the model's predictions are.\t--> Good for multi-class classification problems.\n","- optim.Adam(model.parameters(), lr=0.001)\t--> Adam optimizer adjusts model weights automatically.\t--> Helps model learn faster."],"metadata":{"id":"hJ63vbvXM-0i"}},{"cell_type":"code","source":["#Define Loss Function and Optimizer\n","\n","# Loss function: CrossEntropyLoss (good for classification tasks)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Optimizer: Adam (popular optimizer)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)  # lr = learning rate\n"],"metadata":{"id":"9TQoH-IzM_SO","executionInfo":{"status":"ok","timestamp":1745844048994,"user_tz":-360,"elapsed":4648,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#Create some dummy training data\n","\n","# 100 random samples, each with 5 features\n","X_train = torch.rand((100, 5))\n","\n","# 100 random labels (class 0 or 1)\n","y_train = torch.randint(0, 2, (100,))\n"],"metadata":{"id":"3mo5sp2TXfuo","executionInfo":{"status":"ok","timestamp":1745844050310,"user_tz":-360,"elapsed":502,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["##Training Loop\n","\n","- model.train()\t--> Tells PyTorch to behave differently during training (e.g., Dropout ON).\n","- optimizer.zero_grad()\t--> Clears old gradients (very important before backpropagation).\n","- outputs = model(X_train)\t--> Pass input through model to get predictions.\n","- loss = criterion(outputs, y_train)\t--> Calculates how wrong the model's prediction is.\n","- loss.backward()\t--> Computes gradients (how much each weight should change).\n","- optimizer.step()\t--> Updates the model weights using gradients.\n","- print(...)\t--> Shows the loss to monitor training progress."],"metadata":{"id":"KULvZAXwXu54"}},{"cell_type":"code","source":["#Training Loop\n","\n","epochs = 10  # Number of times we will look at the full dataset\n","\n","for epoch in range(epochs):\n","    model.train()  # Set model to training mode\n","\n","    # 1. Zero the gradients\n","    optimizer.zero_grad()\n","\n","    # 2. Forward pass (make predictions)\n","    outputs = model(X_train)\n","\n","    # 3. Calculate loss\n","    loss = criterion(outputs, y_train)\n","\n","    # 4. Backward pass (compute gradients)\n","    loss.backward()\n","\n","    # 5. Update weights\n","    optimizer.step()\n","\n","    # 6. Print loss\n","    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqLN5zJgYIpm","executionInfo":{"status":"ok","timestamp":1745844052528,"user_tz":-360,"elapsed":199,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}},"outputId":"c0f5c526-5790-4935-e521-fa7447af8ba0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.6909\n","Epoch [2/10], Loss: 0.6895\n","Epoch [3/10], Loss: 0.6882\n","Epoch [4/10], Loss: 0.6868\n","Epoch [5/10], Loss: 0.6855\n","Epoch [6/10], Loss: 0.6843\n","Epoch [7/10], Loss: 0.6831\n","Epoch [8/10], Loss: 0.6820\n","Epoch [9/10], Loss: 0.6810\n","Epoch [10/10], Loss: 0.6800\n"]}]},{"cell_type":"markdown","source":["##Evaluate the Model (Check Accuracy)"],"metadata":{"id":"o07rddppaRdt"}},{"cell_type":"markdown","source":["- model.eval()\t--> Tells model we are in evaluation/testing mode.\tImportant for correct behavior.\n","- with torch.no_grad():\t--> Stops gradient tracking.\tSaves memory, faster evaluation.\n","- outputs = model(X_train)\t--> Gets model predictions.\tForward pass only.\n","- _, predicted = torch.max(outputs, 1)\t--> Picks the class with highest score.\tGet final prediction class.\n","- (predicted == y_train).sum().item()\t--> Counts how many predictions are correct.\tNeeded to compute accuracy.\n","- accuracy = correct / total * 100\t--> Calculates percentage accuracy.\tUnderstand model performance."],"metadata":{"id":"EiT0TqDPbQo7"}},{"cell_type":"code","source":["# model to evaluation mode\n","\n","model.eval()  # Important: turns off training-specific layers (like Dropout, BatchNorm)\n","\n","\n","with torch.no_grad():\n","    # 1. Pass input through model\n","    outputs = model(X_train)\n","\n","    # 2. Get predicted class (highest score)\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # 3. Calculate how many correct predictions\n","    correct = (predicted == y_train).sum().item()\n","\n","    # 4. Calculate accuracy\n","    total = y_train.size(0)\n","    accuracy = correct / total * 100\n","\n","    print(f'Accuracy: {accuracy:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BjgIR5D1aU84","executionInfo":{"status":"ok","timestamp":1745844055041,"user_tz":-360,"elapsed":14,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}},"outputId":"410f0d4b-e02b-4a4b-9a82-7a4adf5fa81e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 56.00%\n"]}]},{"cell_type":"markdown","source":["##Save the model"],"metadata":{"id":"up70Vm5LdC8K"}},{"cell_type":"code","source":["#  Save the model\n","\n","# Save model's parameters (weights)\n","torch.save(model.state_dict(), 'mymodel.pth')  # Saves in a file 'mymodel.pth'\n","print(\"Model saved!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cW04zf-tdDWm","executionInfo":{"status":"ok","timestamp":1745844728095,"user_tz":-360,"elapsed":427,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}},"outputId":"7a729362-62b0-42d8-c047-9e74e3558b99"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved!\n"]}]},{"cell_type":"markdown","source":["#Load the model"],"metadata":{"id":"G82zsz7UdJeP"}},{"cell_type":"code","source":["#Load the model\n","\n","# First, create the model object again\n","model_loaded = MyModel()\n","\n","# Load the saved weights into this model\n","model_loaded.load_state_dict(torch.load('mymodel.pth'))\n","\n","# Always call eval() after loading for inference\n","model_loaded.eval()\n","\n","print(\"Model loaded and ready for evaluation!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DyhPi3ZdJ1w","executionInfo":{"status":"ok","timestamp":1745844766175,"user_tz":-360,"elapsed":7,"user":{"displayName":"Md Noman Hossain","userId":"07089354068876321950"}},"outputId":"a6ec8fa8-db41-4c6b-94ea-b1b14e68c525"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded and ready for evaluation!\n"]}]}]}